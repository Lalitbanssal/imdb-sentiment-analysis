{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Given the IMDB movie review dataset (text reviews + binary sentiment labels), create a reproducible pipeline that:\n",
    "\n",
    "1. Applies a full suite of text preprocessing techniques taught in class (cleaning, tokenization, normalization,  stemming/lemmatization, stopword strategies, etc.).\n",
    "2.  Use Count Vectorizer for building your feature matrices suitable for a Multinomial Naive Bayes classifier.\n",
    "3. Trains and validates Multinomial Naive Bayes models using a test set.\n",
    "4. Quantify the model performance (accuracy, precision, recall, F1, ROC-AUC)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed0a693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3d06bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '../dataset/IMDB Dataset.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea06692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e8f4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df=pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab4531bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24171</th>\n",
       "      <td>Having lived in Japan for several years this m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22717</th>\n",
       "      <td>This is precious. Everything Is Illuminated is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47733</th>\n",
       "      <td>After seeing Meredith in \"Beyond the Prairie\" ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>all i can say is that each time i see CONRACK,...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>After all these years, I am puzzled as to why ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49388</th>\n",
       "      <td>Based on the idea from Gackt, Moon Child took ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44224</th>\n",
       "      <td>SPOILERS THROUGH: &lt;br /&gt;&lt;br /&gt;I really am in t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46005</th>\n",
       "      <td>I liked this movie a lot, but the feeling that...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23379</th>\n",
       "      <td>\"Nuts in May\" may be one of the worst films i ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>I know little or nothing about astronomy, but ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49981</th>\n",
       "      <td>And I repeat, please do not see this movie! Th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46084</th>\n",
       "      <td>for the most part, On Demand delivers some pre...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13167</th>\n",
       "      <td>As a European, the movie is a nice throwback t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22503</th>\n",
       "      <td>Amazing, Astounding, Brilliant, Superb. Those ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25296</th>\n",
       "      <td>I remember years ago BBC1 used to show this mo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9806</th>\n",
       "      <td>I came across this movie while channel surfing...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31136</th>\n",
       "      <td>Spirit: Stallion of the Cimarron is an overall...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31169</th>\n",
       "      <td>Steve Smith has finally run a fairly weak seri...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43147</th>\n",
       "      <td>This movie really, i mean REALLY, sucks. Its g...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>If this is someone's \"favorite\" movie, they ne...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "24171  Having lived in Japan for several years this m...  negative\n",
       "22717  This is precious. Everything Is Illuminated is...  positive\n",
       "47733  After seeing Meredith in \"Beyond the Prairie\" ...  positive\n",
       "4313   all i can say is that each time i see CONRACK,...  positive\n",
       "10544  After all these years, I am puzzled as to why ...  positive\n",
       "49388  Based on the idea from Gackt, Moon Child took ...  positive\n",
       "44224  SPOILERS THROUGH: <br /><br />I really am in t...  positive\n",
       "46005  I liked this movie a lot, but the feeling that...  positive\n",
       "23379  \"Nuts in May\" may be one of the worst films i ...  negative\n",
       "918    I know little or nothing about astronomy, but ...  positive\n",
       "49981  And I repeat, please do not see this movie! Th...  negative\n",
       "46084  for the most part, On Demand delivers some pre...  negative\n",
       "13167  As a European, the movie is a nice throwback t...  positive\n",
       "22503  Amazing, Astounding, Brilliant, Superb. Those ...  positive\n",
       "25296  I remember years ago BBC1 used to show this mo...  positive\n",
       "9806   I came across this movie while channel surfing...  positive\n",
       "31136  Spirit: Stallion of the Cimarron is an overall...  positive\n",
       "31169  Steve Smith has finally run a fairly weak seri...  negative\n",
       "43147  This movie really, i mean REALLY, sucks. Its g...  negative\n",
       "1224   If this is someone's \"favorite\" movie, they ne...  negative"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3df071b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label={\n",
    "    'positive': 1,\n",
    "    'negative' :0,\n",
    "}\n",
    "\n",
    "df['sentiment_label']=df['sentiment'].map(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec2602e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12178</th>\n",
       "      <td>This is another fantasy favorite from Ralph Ba...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28874</th>\n",
       "      <td>I have to say I was very curious on viewing th...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18130</th>\n",
       "      <td>The best bond game made of all systems. It was...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38591</th>\n",
       "      <td>Director/screenwriter Allan Burns seems to hav...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26744</th>\n",
       "      <td>I was not impressed about this film especially...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49769</th>\n",
       "      <td>I've been a fan of Jim Henson and his characte...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41068</th>\n",
       "      <td>I guess this would be a great movie for a true...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15952</th>\n",
       "      <td>This film is too good for words. Its so unbeli...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29587</th>\n",
       "      <td>I think the movie was one sided I watched it r...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47602</th>\n",
       "      <td>I first saw Rob Roy twelve years ago. With lit...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  \\\n",
       "12178  This is another fantasy favorite from Ralph Ba...  positive   \n",
       "28874  I have to say I was very curious on viewing th...  negative   \n",
       "18130  The best bond game made of all systems. It was...  positive   \n",
       "38591  Director/screenwriter Allan Burns seems to hav...  negative   \n",
       "26744  I was not impressed about this film especially...  negative   \n",
       "49769  I've been a fan of Jim Henson and his characte...  negative   \n",
       "41068  I guess this would be a great movie for a true...  negative   \n",
       "15952  This film is too good for words. Its so unbeli...  positive   \n",
       "29587  I think the movie was one sided I watched it r...  negative   \n",
       "47602  I first saw Rob Roy twelve years ago. With lit...  positive   \n",
       "\n",
       "       sentiment_label  \n",
       "12178                1  \n",
       "28874                0  \n",
       "18130                1  \n",
       "38591                0  \n",
       "26744                0  \n",
       "49769                0  \n",
       "41068                0  \n",
       "15952                1  \n",
       "29587                0  \n",
       "47602                1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7c03b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before and After Preprocessing:\n",
      "================================================================================\n",
      "\n",
      "Original: One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "Cleaned:  one reviewers mentioned watching 1 oz episode 'll hooked right exactly happened me.br br first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use word.br br called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home many .. aryans muslims gangstas latinos christians italians irish .... scuffles death stares dodgy dealings shady agreements never far away.br br would say main appeal show due fact goes shows would n't dare forget pretty pictures painted mainstream audiences forget charm forget romance ... oz n't mess around first episode ever saw struck nasty surreal could n't say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards 'll sold nickel inmates 'll kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewing .... thats get touch darker side\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\n",
      "Cleaned:  wonderful little production br br filming technique unassuming oldtimebbc fashion gives comforting sometimes discomforting sense realism entire piece br br actors extremely well chosen michael sheen `` got polari '' voices pat truly see seamless editing guided references williams diary entries well worth watching terrificly written performed piece masterful production one great master 's comedy life br br realism really comes home little things fantasy guard rather use traditional 'dream techniques remains solid disappears plays knowledge senses particularly scenes concerning orton halliwell sets particularly flat halliwell 's murals decorating every surface terribly well done\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\n",
      "Cleaned:  thought wonderful way spend time hot summer weekend sitting air conditioned theater watching lighthearted comedy plot simplistic dialogue witty characters likable even well bread suspected serial killer may disappointed realize match point 2 risk addiction thought proof woody allen still fully control style many us grown love.br br 'd laughed one woody 's comedies years dare say decade 've never impressed scarlet johanson managed tone `` sexy '' image jumped right average spirited young woman.br br may crown jewel career wittier `` devil wears prada '' interesting `` superman '' great comedy go see friends\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\n",
      "Cleaned:  basically 's family little boy jake thinks 's zombie closet parents fighting time.br br movie slower soap opera ... suddenly jake decides become rambo kill zombie.br br ok first 're going make film must decide thriller drama drama movie watchable parents divorcing arguing like real life jake closet totally ruins film expected see boogeyman similar movie instead watched drama meaningless thriller spots.br br 3 10 well playing parents descent dialogs shots jake ignore\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Original: Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case with most of the people we encounter.<br /><br />The acting is good under Mr. Mattei's direction. Steve Buscemi, Rosario Dawson, Carol Kane, Michael Imperioli, Adrian Grenier, and the rest of the talented cast, make these characters come alive.<br /><br />We wish Mr. Mattei good luck and await anxiously for his next work.\n",
      "Cleaned:  petter mattei 's `` love time money '' visually stunning film watch mr. mattei offers us vivid portrait human relations movie seems telling us money power success people different situations encounter br br variation arthur schnitzler 's play theme director transfers action present time new york different characters meet connect one connected one way another next person one seems know previous point contact stylishly film sophisticated luxurious look taken see people live world live habitat.br br thing one gets souls picture different stages loneliness one inhabits big city exactly best place human relations find sincere fulfillment one discerns case people encounter.br br acting good mr. mattei 's direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier rest talented cast make characters come alive.br br wish mr. mattei good luck await anxiously next work\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize NLTK Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Initialize SpaCy model (disable parser and ner for speed since we only need lemmatization)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess a text string:\n",
    "    1. Convert to lowercase\n",
    "    2. Tokenize into words\n",
    "    3. Remove punctuation\n",
    "    4. Remove stopwords (common words like 'the', 'is', 'and')\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to preprocess\n",
    "    \n",
    "    Returns:\n",
    "        str: Cleaned and preprocessed text\n",
    "    \"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # text with normalization challenges\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "\n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters (keep only letters, numbers, and basic punctuation)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\\\"]+', '', text)\n",
    "    \n",
    "\n",
    "\n",
    "    # Tokenize: split text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Filter out stopwords and punctuation\n",
    "    cleaned_tokens = [\n",
    "        word for word in tokens \n",
    "        if word not in stop_words and word not in string.punctuation\n",
    "    ]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "# Apply preprocessing to all reviews\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "print(\"Before and After Preprocessing:\")\n",
    "print(\"=\" * 80)\n",
    "for idx, row in df[:5].iterrows():\n",
    "    print(f\"\\nOriginal: {row['review']}\")\n",
    "    print(f\"Cleaned:  {row['cleaned_review']}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a3b98ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Stems and Lemmas... (SpaCy might take a moment)\n",
      "\n",
      "Comparison of Text Processing:\n",
      "====================================================================================================\n",
      "                                      cleaned_review  \\\n",
      "0  one reviewers mentioned watching 1 oz episode ...   \n",
      "1  wonderful little production br br filming tech...   \n",
      "2  thought wonderful way spend time hot summer we...   \n",
      "3  basically 's family little boy jake thinks 's ...   \n",
      "4  petter mattei 's `` love time money '' visuall...   \n",
      "\n",
      "                                         review_stem  \\\n",
      "0  one review mention watch 1 oz episod 'll hook ...   \n",
      "1  wonder littl product br br film techniqu unass...   \n",
      "2  thought wonder way spend time hot summer weeke...   \n",
      "3  basic 's famili littl boy jake think 's zombi ...   \n",
      "4  petter mattei 's `` love time money '' visual ...   \n",
      "\n",
      "                                        review_lemma  \n",
      "0  one reviewer mention watch 1 oz episode will h...  \n",
      "1  wonderful little production br br filming tech...  \n",
      "2  think wonderful way spend time hot summer week...  \n",
      "3  basically 's family little boy jake think 's z...  \n",
      "4  petter mattei 's ` ` love time money '' visual...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Initialize NLTK Stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Initialize SpaCy model (disable parser and ner for speed since we only need lemmatization)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "def get_stemmed_text(text):\n",
    "    \"\"\"\n",
    "    Uses NLTK PorterStemmer.\n",
    "    Aggressively chops words. e.g., 'generous' -> 'gener'\n",
    "    \"\"\"\n",
    "    tokenized_text = text.split() # Simple split since it's already cleaned\n",
    "    stemmed_words = [stemmer.stem(word) for word in tokenized_text]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "def get_lemmatized_text(text):\n",
    "    \"\"\"\n",
    "    Uses SpaCy.\n",
    "    Reduces words to dictionary root. e.g., 'generous' -> 'generous', 'was' -> 'be'\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    # .lemma_ returns the root form\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# --- Apply to DataFrame ---\n",
    "print(\"Generating Stems and Lemmas... (SpaCy might take a moment)\")\n",
    "\n",
    "# 1. Create Stemmed Column\n",
    "df['review_stem'] = df['cleaned_review'].apply(get_stemmed_text)\n",
    "\n",
    "# 2. Create Lemmatized Column\n",
    "df['review_lemma'] = df['cleaned_review'].apply(get_lemmatized_text)\n",
    "\n",
    "# --- Comparison ---\n",
    "print(\"\\nComparison of Text Processing:\")\n",
    "print(\"=\" * 100)\n",
    "# Let's look at a specific example where they might differ\n",
    "# We display the first 5 rows\n",
    "pd.set_option('display.max_colwidth', 50) # Set visual width to see more text\n",
    "print(df[['cleaned_review', 'review_stem', 'review_lemma']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fecf09a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple \n",
      "Vocabulary size: 141223 unique words\n",
      "\n",
      "using stemming\n",
      "Vocabulary size: 116617 unique words\n",
      "\n",
      "using lemmatization\n",
      "Vocabulary size: 129556 unique words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Feature Extraction - Convert text to numbers\n",
    "# We'll use CountVectorizer (Bag of Words approach)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "# This will create a vocabulary of all unique words and count their occurrences\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer1 = CountVectorizer()\n",
    "vectorizer2 = CountVectorizer()\n",
    "# Fit the vectorizer on our cleaned reviews and transform them to numerical vectors\n",
    "X = vectorizer.fit_transform(df['cleaned_review'])\n",
    "X1=vectorizer1.fit_transform(df['review_stem'])\n",
    "X2=vectorizer2.fit_transform(df['review_lemma'])\n",
    "# Get the feature names (vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_names1 = vectorizer1.get_feature_names_out()\n",
    "feature_names2 = vectorizer2.get_feature_names_out()\n",
    "\n",
    "print('Simple ')\n",
    "print(f\"Vocabulary size: {len(feature_names)} unique words\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print('using stemming')\n",
    "print(f\"Vocabulary size: {len(feature_names1)} unique words\\n\")\n",
    "\n",
    "print('using lemmatization')\n",
    "print(f\"Vocabulary size: {len(feature_names2)} unique words\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8871105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Accuracy (Simple): 0.8615\n",
      "Accuracy (Stemmed): 0.8579\n",
      "Accuracy (Lemma):   0.8564\n",
      "============================================================\n",
      "\n",
      "Detailed Report for Lemmatization Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86      4961\n",
      "           1       0.87      0.84      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "y = df['sentiment_label'] \n",
    "\n",
    "# 2. Split Data (You did this correctly, we just need to use them now!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train1, X_test1, _, _ = train_test_split(X1, y, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, _, _ = train_test_split(X2, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train Models (FIT ON TRAIN DATA ONLY)\n",
    "clf_simple = MultinomialNB()\n",
    "clf_simple.fit(X_train, y_train)\n",
    "\n",
    "clf_stem = MultinomialNB()\n",
    "clf_stem.fit(X_train1, y_train)\n",
    "\n",
    "clf_lemma = MultinomialNB()\n",
    "clf_lemma.fit(X_train2, y_train)\n",
    "\n",
    "# 4. Predict (PREDICT ON TEST DATA)\n",
    "# We use the specific classifier for its specific data type\n",
    "pred_simple = clf_simple.predict(X_test)\n",
    "pred_stem   = clf_stem.predict(X_test1)\n",
    "pred_lemma  = clf_lemma.predict(X_test2)\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy (Simple): {accuracy_score(y_test, pred_simple):.4f}\")\n",
    "print(f\"Accuracy (Stemmed): {accuracy_score(y_test, pred_stem):.4f}\")\n",
    "print(f\"Accuracy (Lemma):   {accuracy_score(y_test, pred_lemma):.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 6. Detailed Classification Report (Example for Lemmatization)\n",
    "print(\"\\nDetailed Report for Lemmatization Model:\")\n",
    "print(classification_report(y_test, pred_lemma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1675016c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9294\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix\n",
    "\n",
    "# Get probabilities for the positive class (class 1)\n",
    "# simple_clf was trained in the previous step\n",
    "y_proba = clf_simple.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 1. Calculate ROC-AUC Score\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(f\"ROC-AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# 2. Plot Confusion Matrix\n",
    "cm = confusion_matrix(y_test, pred_simple)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (Simple Cleaning)')\n",
    "plt.xticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "plt.yticks([0.5, 1.5], ['Negative', 'Positive'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65e0cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TF-IDF Model...\n",
      "\n",
      "========================================\n",
      "Simple Count Accuracy: 0.8615 (Benchmark)\n",
      "TF-IDF Accuracy:       0.8707\n",
      "========================================\n",
      "SUCCESS: TF-IDF improved the model!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print(\"Training TF-IDF Model...\")\n",
    "\n",
    "# 1. Initialize TF-IDF Vectorizer\n",
    "# We use the 'cleaned_review' column since it performed best\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Transform the text\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# 3. Split Data (Stratify ensures balanced classes)\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(\n",
    "    X_tfidf, df['sentiment_label'], test_size=0.2, random_state=42, stratify=df['sentiment_label']\n",
    ")\n",
    "\n",
    "# 4. Train Multinomial Naive Bayes\n",
    "clf_tfidf = MultinomialNB()\n",
    "clf_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "pred_tfidf = clf_tfidf.predict(X_test_tfidf)\n",
    "acc_tfidf = accuracy_score(y_test, pred_tfidf)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Simple Count Accuracy: 0.8615 (Benchmark)\")\n",
    "print(f\"TF-IDF Accuracy:       {acc_tfidf:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check if we improved\n",
    "if acc_tfidf > 0.8615:\n",
    "    print(\"SUCCESS: TF-IDF improved the model!\")\n",
    "else:\n",
    "    print(\"RESULT: TF-IDF did not improve the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53c7ec1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training TF-IDF with Bigrams...\n",
      "\n",
      "========================================\n",
      "TF-IDF (Unigrams): 0.8707\n",
      "TF-IDF (Bigrams):  0.8909\n",
      "========================================\n",
      "SUCCESS: Context (Bigrams) improved the model!\n"
     ]
    }
   ],
   "source": [
    "print(\"Training TF-IDF with Bigrams...\")\n",
    "\n",
    "# 1. Initialize TF-IDF with N-grams\n",
    "# ngram_range=(1, 2) means: \"Look for single words AND pairs of words\"\n",
    "tfidf_ngram = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "# 2. Transform\n",
    "X_ngram = tfidf_ngram.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# 3. Split\n",
    "X_train_ng, X_test_ng, y_train, y_test = train_test_split(\n",
    "    X_ngram, df['sentiment_label'], test_size=0.2, random_state=42, stratify=df['sentiment_label']\n",
    ")\n",
    "\n",
    "# 4. Train\n",
    "clf_ngram = MultinomialNB()\n",
    "clf_ngram.fit(X_train_ng, y_train)\n",
    "\n",
    "# 5. Evaluate\n",
    "pred_ngram = clf_ngram.predict(X_test_ng)\n",
    "acc_ngram = accuracy_score(y_test, pred_ngram)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"TF-IDF (Unigrams): {acc_tfidf:.4f}\")\n",
    "print(f\"TF-IDF (Bigrams):  {acc_ngram:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "if acc_ngram > acc_tfidf:\n",
    "    print(\"SUCCESS: Context (Bigrams) improved the model!\")\n",
    "else:\n",
    "    print(\"RESULT: Bigrams didn't help (or added too much noise).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8de927a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression on Bigram TF-IDF Features...\n",
      "\n",
      "=============================================\n",
      "Naive Bayes (Bigrams):        0.8909\n",
      "Logistic Regression (Bigrams): 0.8958\n",
      "=============================================\n",
      "\n",
      "Top 10 Most POSITIVE Phrases:\n",
      "            Phrase  Coefficient\n",
      "1276989      great    10.942139\n",
      "980112   excellent     8.276601\n",
      "301334        best     6.837873\n",
      "3241769  wonderful     6.050952\n",
      "2142089    perfect     6.040197\n",
      "1732974       love     5.896897\n",
      "129601     amazing     5.789907\n",
      "1736957      loved     5.449114\n",
      "3191330       well     5.355308\n",
      "1179086        fun     5.215730\n",
      "\n",
      "Top 10 Most NEGATIVE Phrases:\n",
      "           Phrase  Coefficient\n",
      "244264        bad   -12.117377\n",
      "3261460     worst   -11.299266\n",
      "233306      awful    -8.574609\n",
      "3163973     waste    -7.739420\n",
      "353762     boring    -7.685627\n",
      "2009640   nothing    -7.179298\n",
      "2906279  terrible    -7.100265\n",
      "2218330      poor    -7.020895\n",
      "955208       even    -5.855419\n",
      "2812380    stupid    -5.845052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(\"Training Logistic Regression on Bigram TF-IDF Features...\")\n",
    "\n",
    "# 1. Initialize Logistic Regression\n",
    "# C=1.0 is the regularization strength. Smaller C = stronger regularization (prevents overfitting)\n",
    "log_reg_ng = LogisticRegression(max_iter=1000, C=1.0, random_state=42)\n",
    "\n",
    "# 2. Train on the Bigram data you just created (X_train_ng)\n",
    "log_reg_ng.fit(X_train_ng, y_train)\n",
    "\n",
    "# 3. Predict and Evaluate\n",
    "pred_log_ng = log_reg_ng.predict(X_test_ng)\n",
    "acc_log_ng = accuracy_score(y_test, pred_log_ng)\n",
    "\n",
    "print(\"\\n\" + \"=\"*45)\n",
    "print(f\"Naive Bayes (Bigrams):        0.8909\")\n",
    "print(f\"Logistic Regression (Bigrams): {acc_log_ng:.4f}\")\n",
    "print(\"=\"*45)\n",
    "\n",
    "# --- The \"Magic\" Part: Inspecting Learned Phrases ---\n",
    "# Get the feature names (words and phrases)\n",
    "feature_names = tfidf_ngram.get_feature_names_out()\n",
    "coefficients = log_reg_ng.coef_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({'Phrase': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "# Sort to find the most influential phrases\n",
    "top_positive = coef_df.sort_values(by='Coefficient', ascending=False).head(10)\n",
    "top_negative = coef_df.sort_values(by='Coefficient', ascending=True).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Most POSITIVE Phrases:\")\n",
    "print(top_positive)\n",
    "\n",
    "print(\"\\nTop 10 Most NEGATIVE Phrases:\")\n",
    "print(top_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_reviews = [\n",
    "    \"This is an excellent movie with great performances!\",\n",
    "    \"Awful experience, very disappointing.\",\n",
    "    \"Absolutely loved it, highly recommended!\"\n",
    "]\n",
    "\n",
    "print(\"Testing with New Reviews:\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "189a6178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with New Reviews:\n",
      "================================================================================\n",
      "Review: This is an excellent movie with great performances!\n",
      "Prediction: Positive (99.88% confidence)\n",
      "--------------------------------------------------\n",
      "Review: Awful experience, very disappointing.\n",
      "Prediction: Negative (96.73% confidence)\n",
      "--------------------------------------------------\n",
      "Review: Absolutely loved it, highly recommended!\n",
      "Prediction: Positive (98.21% confidence)\n",
      "--------------------------------------------------\n",
      "Review: It was okay, not the best but certainly not the worst.\n",
      "Prediction: Negative (79.18% confidence)\n",
      "--------------------------------------------------\n",
      "Review: I expected to hate it, but I was pleasantly surprised.\n",
      "Prediction: Positive (86.66% confidence)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The new data\n",
    "new_reviews = [\n",
    "    \"This is an excellent movie with great performances!\",\n",
    "    \"Awful experience, very disappointing.\",\n",
    "    \"Absolutely loved it, highly recommended!\",\n",
    "    \"It was okay, not the best but certainly not the worst.\", # Added a tricky neutral one\n",
    "    \"I expected to hate it, but I was pleasantly surprised.\" # Added a tricky mixed sentiment\n",
    "]\n",
    "\n",
    "print(\"Testing with New Reviews:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Apply the SAME preprocessing\n",
    "cleaned_new_reviews = [preprocess_text(r) for r in new_reviews]\n",
    "\n",
    "# 2. Apply the SAME vectorizer (Transform only!)\n",
    "# We use the 'tfidf_ngram' vectorizer because that's what 'log_reg_ng' expects\n",
    "X_new = tfidf_ngram.transform(cleaned_new_reviews)\n",
    "\n",
    "# 3. Predict using the Logistic Regression model\n",
    "new_predictions = log_reg_ng.predict(X_new)\n",
    "new_probs = log_reg_ng.predict_proba(X_new)\n",
    "\n",
    "# 4. Display Results\n",
    "for i, review in enumerate(new_reviews):\n",
    "    sentiment = \"Positive\" if new_predictions[i] == 1 else \"Negative\"\n",
    "    confidence = new_probs[i].max() * 100 # Get the probability of the predicted class\n",
    "    \n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Prediction: {sentiment} ({confidence:.2f}% confidence)\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60e9ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  created or already existed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs('model', exist_ok=True)\n",
    "    print(f\"Directory  created or already existed.\")\n",
    "except OSError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6ce08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving artifacts...\n",
      "Saved using Joblib: .joblib files created.\n",
      "Saved using Pickle: .pkl files created.\n",
      "\n",
      "All files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "\n",
    "print(\"Saving artifacts...\")\n",
    "\n",
    "# --- Method 1: Using Joblib (Recommended for Scikit-Learn) ---\n",
    "# Joblib is often faster and more efficient for objects containing large numpy arrays\n",
    "joblib.dump(log_reg_ng, 'model/imdb_sentiment_model.joblib')\n",
    "joblib.dump(tfidf_ngram, 'model/imdb_tfidf_vectorizer.joblib')\n",
    "print(\"Saved using Joblib: .joblib files created.\")\n",
    "\n",
    "# --- Method 2: Using Pickle (Standard Python) ---\n",
    "# Pickle is the standard Python way to serialize objects\n",
    "with open('imdb_sentiment_model.pkl', 'wb') as f:\n",
    "    pickle.dump(log_reg_ng, f)\n",
    "\n",
    "with open('imdb_tfidf_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_ngram, f)\n",
    "print(\"Saved using Pickle: .pkl files created.\")\n",
    "\n",
    "print(\"\\nAll files saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ade4752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lb368\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lb368\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pipeline...\n",
      " Pipeline saved successfully as 'sentiment_pipeline.joblib'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import joblib\n",
    "\n",
    "# NLTK Imports\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# sklearn Imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. GLOBAL INITIALIZATION (Run once) ---\n",
    "# Download necessary NLTK data (if not already present)\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize these OUTSIDE the function so they are created only once\n",
    "my_stemmer = PorterStemmer()\n",
    "my_stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# --- 2. Define the Preprocessing Function ---\n",
    "# It uses the global 'my_stemmer' and 'my_stop_words'\n",
    "def preprocess_text(text_list):\n",
    "    clean_data = []\n",
    "    for text in text_list:\n",
    "        # 1. Lowercase & Normalization\n",
    "        text = text.lower()\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # 2. Remove URLs, Handles, Special Characters\n",
    "        text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s.,!?\\'\\\"]+', '', text)\n",
    "        \n",
    "        # 3. Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # 4. Stem & Remove Stopwords\n",
    "        # Uses the global variables defined above\n",
    "        cleaned_tokens = [\n",
    "            my_stemmer.stem(word) for word in tokens \n",
    "            if word not in my_stop_words and word not in string.punctuation\n",
    "        ]\n",
    "        clean_data.append(' '.join(cleaned_tokens))\n",
    "    \n",
    "    return clean_data\n",
    "\n",
    "# --- 3. Build & Train Pipeline ---\n",
    "# validate=False is required for text data\n",
    "cleaner = FunctionTransformer(preprocess_text, validate=False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('cleaner', cleaner),\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, C=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"Training pipeline...\")\n",
    "# Assuming 'df' is your dataframe from previous steps\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    df['review'], df['sentiment_label'], \n",
    "    test_size=0.2, random_state=42, stratify=df['sentiment_label']\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train_raw, y_train)\n",
    "\n",
    "# --- 4. Save ---\n",
    "joblib.dump(pipeline, 'sentiment_pipeline.joblib')\n",
    "print(\" Pipeline saved successfully as 'sentiment_pipeline.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
